<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
      Amortized Probabilistic Conditioning for Optimization, Simulation and
      Inference | ACE Project Page
    </title>
    <meta
      name="description"
      content="Project page for the paper 'Amortized Probabilistic Conditioning for Optimization, Simulation and Inference' (ACE) by Chang, Loka, Huang, Remes, Kaski, Acerbi (AISTATS 2025)"
    />
    <meta
      property="og:title"
      content="Amortized Probabilistic Conditioning for Optimization, Simulation and Inference"
    />
    <meta property="og:locale" content="en_US" />
    <meta
      property="og:description"
      content="This website contains information about the ACE framework, a transformer-based meta-learning model that provides a unified approach for probabilistic conditioning and prediction across various machine learning tasks."
    />
    <style>
      :root {
        /* Main color palette - more modern and cohesive */
        --primary-color: #2563eb;          /* Blue 600 */
        --primary-light: #93c5fd;          /* Blue 300 */
        --primary-dark: #1e40af;           /* Blue 800 */
        --secondary-color: #1e293b;        /* Slate 800 */
        --accent-color: #f97316;           /* Orange 500 */
        --accent-light: #fdba74;           /* Orange 300 */
        --accent-dark: #c2410c;            /* Orange 700 */

        /* Background and text colors */
        --light-bg: #f8fafc;               /* Slate 50 */
        --dark-bg: #1e293b;                /* Slate 800 */
        --card-bg: #ffffff;                /* White */
        --text-color: #334155;             /* Slate 600 */
        --light-text: #f8fafc;             /* Slate 50 */
        --muted-text: #64748b;             /* Slate 500 */
        --heading-color: #0f172a;          /* Slate 900 */

        /* UI element colors */
        --border-color: #e2e8f0;           /* Slate 200 */
        --code-bg: #f1f5f9;                /* Slate 100 */
        --blockquote-bg: #eff6ff;          /* Blue 50 */
        --blockquote-border: #3b82f6;      /* Blue 500 */
        --highlight-bg: #fef3c7;           /* Amber 100 */
        --header-gradient-start: #1e40af;  /* Blue 800 */
        --header-gradient-end: #3b82f6;    /* Blue 500 */

        /* Spacing */
        --spacing-xs: 0.25rem;
        --spacing-sm: 0.5rem;
        --spacing-md: 1rem;
        --spacing-lg: 1.5rem;
        --spacing-xl: 2rem;
        --spacing-2xl: 3rem;

        /* Shadows */
        --shadow-sm: 0 1px 2px rgba(0, 0, 0, 0.05);
        --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);

        /* Transitions */
        --transition-fast: 150ms ease;
        --transition-normal: 250ms ease;
        --transition-slow: 350ms ease;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
        line-height: 1.7;
        color: var(--text-color);
        background-color: var(--light-bg);
        max-width: 1200px;
        margin: 0 auto;
        padding: var(--spacing-lg);
        font-size: 1.05rem;
      }

      a {
        color: var(--primary-color);
        text-decoration: none;
        transition: color var(--transition-fast);
        font-weight: 500;
      }

      a:hover {
        color: var(--primary-dark);
        text-decoration: underline;
      }

      h1,
      h2,
      h3,
      h4,
      h5,
      h6 {
        margin: 1.8rem 0 1rem;
        line-height: 1.2;
        color: var(--heading-color);
        font-weight: 700;
        letter-spacing: -0.01em;
      }

      h1 {
        font-size: 2.6rem;
        margin-top: 0;
        margin-bottom: 0.8rem;
        letter-spacing: -0.02em;
        background: linear-gradient(to right, var(--primary-dark), var(--primary-color));
        -webkit-background-clip: text;
        background-clip: text;
        color: transparent;
        display: inline-block;
        padding-bottom: 0.3rem;
        font-weight: 800;
      }

      h2 {
        font-size: 1.9rem;
        padding-bottom: 0.5rem;
        border-bottom: 1px solid var(--border-color);
        margin-top: 2.5rem;
      }

      h3 {
        font-size: 1.5rem;
        color: var(--secondary-color);
        position: relative;
        padding-left: 1rem;
      }

      h3::before {
        content: "";
        position: absolute;
        left: 0;
        top: 0.4rem;
        height: 1.5rem;
        width: 4px;
        background-color: var(--primary-color);
        border-radius: 2px;
      }

      h4 {
        font-size: 1.25rem;
        color: var(--muted-text);
      }

      p,
      ul,
      ol {
        margin-bottom: 1.4rem;
      }

      strong {
        color: var(--heading-color);
      }

      ul,
      ol {
        padding-left: 1.5rem;
      }

      img {
        max-width: 100%;
        height: auto;
        display: block;
        margin: 2rem auto;
        border-radius: 8px;
        box-shadow: var(--shadow-md);
        transition: transform var(--transition-normal), box-shadow var(--transition-normal);
        cursor: pointer; /* Show pointer cursor to indicate clickability */
      }

      img:hover {
        transform: scale(1.02);
        box-shadow: var(--shadow-lg);
      }

      .caption {
        text-align: center;
        margin-top: -1rem;
        margin-bottom: 2rem;
        font-style: italic;
        color: var(--muted-text);
        font-size: 0.92rem;
        padding: 0 var(--spacing-lg);
      }

      code {
        font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo,
          monospace;
        background: var(--code-bg);
        padding: 0.2em 0.4em;
        border-radius: 4px;
        font-size: 0.9em;
        color: var(--primary-dark);
      }

      pre {
        background: var(--code-bg);
        padding: 1rem;
        overflow-x: auto;
        border-radius: 5px;
        margin-bottom: 1.5rem;
      }

      pre code {
        background: none;
        padding: 0;
      }

      blockquote {
        background-color: var(--blockquote-bg);
        border-left: 4px solid var(--blockquote-border);
        padding: 1.5rem 1.75rem;
        margin: 2.5rem 0;
        border-radius: 0 12px 12px 0;
        box-shadow: var(--shadow-md);
        position: relative;
      }

      blockquote::before {
        content: """;
        position: absolute;
        top: -0.5rem;
        left: 0.5rem;
        font-size: 4rem;
        color: var(--primary-light);
        line-height: 1;
        opacity: 0.3;
      }

      blockquote p:last-child {
        margin-bottom: 0;
      }

      .header {
        text-align: center;
        margin-bottom: 3.5rem;
        padding: 2.5rem 1.5rem;
        background: linear-gradient(135deg, var(--light-bg) 0%, var(--primary-light) 100%);
        border-radius: 16px;
        box-shadow: var(--shadow-lg);
        position: relative;
        overflow: hidden;
      }

      .header::before {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 6px;
        background: linear-gradient(to right, var(--primary-dark), var(--accent-color));
        border-radius: 16px 16px 0 0;
      }

      .authors {
        margin: 1.25rem 0;
        font-size: 1.15rem;
        line-height: 1.8;
      }

      .affiliations {
        font-size: 0.95rem;
        margin-bottom: 1.25rem;
        color: var(--muted-text);
        background-color: rgba(255, 255, 255, 0.7);
        padding: 1rem 1.5rem;
        border-radius: 8px;
        display: inline-block;
      }

      .conference {
        font-weight: 700;
        margin: 1.5rem 0;
        color: var(--accent-color);
        padding: 0.5rem 1rem;
        background-color: rgba(255, 255, 255, 0.8);
        border-radius: 6px;
        display: inline-block;
      }

      .resources {
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        gap: 12px;
        margin: 1.75rem 0 0.75rem;
      }

      .btn {
        display: inline-flex;
        align-items: center;
        justify-content: center;
        padding: 0.75rem 1.5rem;
        background-color: var(--primary-color);
        color: white;
        border-radius: 8px;
        text-decoration: none;
        font-weight: 600;
        transition: all var(--transition-normal);
        border: none;
        box-shadow: var(--shadow-md);
        position: relative;
        overflow: hidden;
      }

      .btn::after {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(255, 255, 255, 0.1);
        transform: translateY(100%);
        transition: transform var(--transition-fast);
        z-index: 1;
      }

      .btn span {
        position: relative;
        z-index: 2;
      }

      .btn:hover {
        background-color: var(--primary-dark);
        text-decoration: none;
        transform: translateY(-3px);
        box-shadow: var(--shadow-lg);
      }

      .btn:hover::after {
        transform: translateY(0);
      }

      .btn:active {
        transform: translateY(-1px);
      }

      .tldr {
        background-color: var(--card-bg);
        padding: 2rem;
        border-radius: 12px;
        margin: 2.5rem 0;
        border: 1px solid var(--border-color);
        box-shadow: var(--shadow-lg);
        position: relative;
        overflow: hidden;
      }

      .tldr::before {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 6px;
        background: linear-gradient(to right, var(--primary-color), var(--accent-color));
      }

      .tldr h3 {
        margin-top: 0;
        color: var(--primary-color);
        font-size: 1.5rem;
        margin-bottom: 1.25rem;
        padding-left: 0;
      }

      .tldr h3::before {
        display: none;
      }

      .citation {
        background-color: var(--code-bg);
        padding: 2rem;
        border-radius: 12px;
        margin: 2.5rem 0;
        border: 1px solid var(--border-color);
        font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo,
          monospace;
        white-space: pre-wrap;
        font-size: 0.9rem;
        position: relative; /* For positioning the copy button */
        overflow-x: auto; /* For horizontal scrolling if needed */
        box-shadow: var(--shadow-md);
        line-height: 1.6;
      }

      /* Style for the copy button */
      .copy-btn {
        position: absolute;
        top: 0.75rem;
        right: 0.75rem;
        background-color: var(--card-bg);
        color: var(--primary-color);
        border: 1px solid var(--border-color);
        border-radius: 8px;
        width: 36px;
        height: 36px;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        opacity: 0.9;
        transition: all var(--transition-fast);
      }

      .copy-btn:hover {
        opacity: 1;
        color: var(--primary-dark);
        background-color: var(--light-bg);
        transform: translateY(-2px);
        box-shadow: var(--shadow-sm);
      }

      .copy-btn:active {
        transform: translateY(0);
      }

      .copy-btn.copied {
        background-color: var(--primary-color);
        color: white;
      }

      .copy-btn svg {
        width: 18px;
        height: 18px;
        stroke: currentColor;
        stroke-width: 2;
        stroke-linecap: round;
        stroke-linejoin: round;
        fill: none;
      }

      table {
        width: 100%;
        border-collapse: collapse;
        margin: 1.5rem 0;
      }

      table th,
      table td {
        padding: 0.75rem;
        text-align: left;
        border: 1px solid var(--border-color);
      }

      table th {
        background-color: var(--light-bg);
        font-weight: 600;
      }

      table tr:nth-child(even) {
        background-color: var(--light-bg);
      }

      .two-column {
        display: flex;
        gap: 2rem;
        margin: 1.5rem 0;
      }

      .two-column > div {
        flex: 1;
      }

      .highlight {
        background-color: var(--highlight-bg);
        padding: 2rem;
        border-radius: 12px;
        margin: 2.5rem 0;
        box-shadow: var(--shadow-md);
        position: relative;
      }

      .highlight::before {
        content: "";
        position: absolute;
        top: -10px;
        right: 30px;
        width: 22px;
        height: 22px;
        background-color: var(--accent-color);
        border-radius: 50%;
        opacity: 0.15;
      }

      .highlight::after {
        content: "";
        position: absolute;
        bottom: -15px;
        left: 40px;
        width: 36px;
        height: 36px;
        background-color: var(--primary-color);
        border-radius: 50%;
        opacity: 0.1;
      }

      .highlight h3 {
        color: var(--primary-dark);
        margin-top: 0;
        border-bottom: 1px solid var(--accent-light);
        padding-bottom: 0.75rem;
        margin-bottom: 1.25rem;
        padding-left: 0;
      }

      .highlight h3::before {
        display: none;
      }

      @media (max-width: 768px) {
        .two-column {
          flex-direction: column;
        }
      }

      footer {
        margin-top: 4rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-color);
        text-align: center;
        font-size: 0.95rem;
        color: var(--muted-text);
      }

      footer a {
        color: var(--primary-color);
      }

      footer p {
        margin-bottom: 1rem;
      }

      .responsive-img {
        width: 100%;
        display: block;
        margin: auto;
        margin-bottom: 1.5em;
      }

      .responsive-img-large {
        width: 100%;
        display: block;
        margin: auto;
        margin-bottom: 1.5em;
      }

      /* Lightbox styles */
      .lightbox {
        display: none;
        position: fixed;
        z-index: 1000;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(0, 0, 0, 0.85);
        opacity: 0;
        transition: opacity 0.3s ease;
        justify-content: center;
        align-items: center;
        overflow: hidden;
      }

      .lightbox.active {
        display: flex;
        opacity: 1;
      }

      .lightbox-content {
        max-width: 90%;
        max-height: 90%;
        border-radius: 4px;
        box-shadow: var(--shadow-xl);
        position: relative;
        transform: scale(0.95);
        transition: transform 0.3s ease;
      }

      .lightbox.active .lightbox-content {
        transform: scale(1);
      }

      .lightbox-close {
        position: absolute;
        top: 15px;
        right: 15px;
        color: white;
        font-size: 24px;
        background-color: rgba(0, 0, 0, 0.5);
        width: 40px;
        height: 40px;
        border-radius: 50%;
        display: flex;
        justify-content: center;
        align-items: center;
        cursor: pointer;
        transition: background-color 0.2s ease;
      }

      .lightbox-close:hover {
        background-color: rgba(0, 0, 0, 0.8);
      }

      .back-to-top {
        position: fixed;
        bottom: 20px;
        right: 20px;
        background-color: var(--primary-color);
        color: white;
        width: 50px;
        height: 50px;
        border-radius: 50%;
        display: flex;
        justify-content: center;
        align-items: center;
        text-decoration: none;
        opacity: 0;
        transform: translateY(20px);
        transition: opacity 0.3s ease, transform 0.3s ease, background-color 0.2s ease;
        box-shadow: var(--shadow-md);
        pointer-events: none;
        z-index: 100;
        -webkit-tap-highlight-color: transparent; /* Remove tap highlight on mobile */
      }

      .back-to-top.visible {
        opacity: 0.9;
        transform: translateY(0);
        pointer-events: auto;
      }

      .back-to-top:hover {
        background-color: var(--primary-dark);
        opacity: 1;
        text-decoration: none;
      }

      .back-to-top:focus {
        outline: 2px solid var(--primary-light);
        outline-offset: 2px;
      }

      /* Reset active state specifically for the back-to-top button */
      .back-to-top-active {
        background-color: var(--primary-dark) !important;
      }

      /* Ensure no persistent hover effects on touch devices */
      @media (hover: none) {
        .back-to-top:hover, .back-to-top:active {
          background-color: var(--primary-color);
        }

        .back-to-top-active {
          background-color: var(--primary-dark) !important;
        }
      }

      /* Architecture figure collapsible styles */
      .architecture-details {
        margin: 2rem 0;
        border: 1px solid var(--border-color);
        border-radius: 12px;
        overflow: hidden;
        box-shadow: var(--shadow-md);
      }

      .collapsible {
        background-color: var(--light-bg);
        color: var(--primary-color);
        cursor: pointer;
        padding: 1rem 1.5rem;
        width: 100%;
        text-align: left;
        border: none;
        outline: none;
        font-size: 1.05rem;
        font-weight: 600;
        transition: all var(--transition-normal);
        display: flex;
        justify-content: space-between;
        align-items: center;
        border-radius: 12px;
      }

      .collapsible:hover, .collapsible:focus {
        background-color: var(--primary-light);
        color: var(--primary-dark);
      }

      .collapsible:focus {
        outline: 2px solid var(--primary-light);
        outline-offset: 2px;
      }

      .collapsible-icon {
        transition: transform var(--transition-normal);
      }

      .collapsible[aria-expanded="true"] .collapsible-icon {
        transform: rotate(180deg);
      }

      .hide-text {
        display: none;
      }

      .collapsible[aria-expanded="true"] .show-text {
        display: none;
      }

      .collapsible[aria-expanded="true"] .hide-text {
        display: inline;
      }

      .content {
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.6s ease;
        background-color: var(--card-bg);
      }

      .arch-figure-container {
        padding: 1.5rem;
      }

      .arch-figure-section {
        margin-bottom: 2rem;
      }

      .arch-explanation {
        background-color: var(--light-bg);
        padding: 1.5rem;
        border-radius: 8px;
        margin-top: 1.5rem;
      }

      .arch-explanation p {
        margin-bottom: 1rem;
      }

      .arch-explanation ul {
        margin-bottom: 1rem;
        padding-left: 2rem;
      }

      /* On screens wider than 768px (typical tablet/laptop breakpoint) */
      @media (min-width: 768px) {
        .responsive-img {
          width: 50%;
        }
        .responsive-img-large {
          width: 90%;
        }

        .arch-figure-container {
          padding: 2rem;
        }
      }
    </style>
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [
            ["$", "$"],
            ["\\(", "\\)"],
          ],
          displayMath: [
            ["$$", "$$"],
            ["\\[", "\\]"],
          ],
          processEscapes: true,
          processEnvironments: true,
        },
        options: {
          ignoreHtmlClass: "tex2jax_ignore",
          processHtmlClass: "tex2jax_process",
        },
      };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
  </head>
  <body>
    <div class="header">
      <h1>
        Amortized Probabilistic Conditioning for Optimization, Simulation and
        Inference
      </h1>
      <div class="authors">
        Paul E. Chang<sup>*1</sup>, Nasrulloh Loka<sup>*1</sup>, Daolang
        Huang<sup>*2</sup>, Ulpu Remes<sup>3</sup>, Samuel Kaski<sup>2,4</sup>,
        Luigi Acerbi<sup>1</sup>
      </div>
      <div class="affiliations">
        <sup>1</sup>Department of Computer Science, University of Helsinki,
        Helsinki, Finland<br />
        <sup>2</sup>Department of Computer Science, Aalto University, Espoo,
        Finland<br />
        <sup>3</sup>Department of Mathematics and Statistics, University of
        Helsinki, Helsinki, Finland<br />
        <sup>4</sup>Department of Computer Science, University of Manchester,
        Manchester, United Kingdom<br />
        <sup>*</sup>Equal contribution
      </div>
      <div class="conference">
        Accepted to the 28th International Conference on Artificial Intelligence
        and Statistics (AISTATS 2025)
      </div>
      <div class="resources">
        <a
          href="https://github.com/acerbilab/amortized-conditioning-engine/"
          class="btn"
          aria-label="View source code on GitHub"
          ><span>Code</span></a
        >
        <a
          href="https://arxiv.org/abs/2410.15320"
          class="btn"
          aria-label="Read paper on arXiv"
          ><span>Paper</span></a
        >
        <a
          href="https://bsky.app/profile/lacerbi.bsky.social/post/3ljpc4zkyl22k"
          class="btn"
          aria-label="Read social thread"
          ><span>Social</span></a
        >
        <a
          href="https://github.com/acerbilab/amortized-conditioning-engine/tree/main/docs/paper"
          class="btn"
          aria-label="View paper in Markdown"
          ><span>Markdown</span></a
        >
      </div>
    </div>

    <div class="tldr">
      <h3>TL;DR</h3>
      <p>
        We introduce the <strong>Amortized Conditioning Engine (ACE)</strong>, a
        transformer-based meta-learning model that enables flexible
        probabilistic conditioning and prediction for machine learning tasks.
        ACE can condition on both observed data and latent variables, include
        priors at runtime, and output predictive distributions for both data and
        latents. This general framework unifies and simplifies diverse ML tasks
        like image completion, Bayesian optimization, and simulation-based
        inference.
      </p>
    </div>

    <!-- prettier-ignore -->
    <div class="citation">
    @article{chang2025amortized, 
      title={Amortized Probabilistic Conditioning for Optimization, Simulation and Inference}, 
      author={Chang, Paul E and Loka, Nasrulloh and Huang, Daolang and Remes, Ulpu and Kaski, Samuel and Acerbi, Luigi},
      journal={28th Int. Conf. on Artificial Intelligence & Statistics (AISTATS 2025)},
      year={2025}
    }
    </div>

    <h2>Introduction</h2>
    <p>
      Amortization, or pre-training, is a crucial technique for improving
      computational efficiency and generalization across many machine learning
      tasks. This paper capitalizes on the observation that many machine
      learning problems reduce to predicting data and task-relevant latent
      variables after conditioning on other data and latents. Moreover, in many
      scenarios, the user has exact or probabilistic information (priors) about
      task-relevant variables that they would like to leverage, but
      incorporating such prior knowledge is challenging and often requires
      dedicated, expensive solutions.
    </p>

    <p>
      Consider Bayesian optimization (BO), where the goal is to find the
      location $\mathbf{x}_{\text{opt}}$ and value $y_{\text{opt}}$ of the
      global minimum of a function. These are latent variables, distinct from
      the observed data $\mathcal{D}_{N}$ consisting of function values at
      queried locations. Following information-theoretical principles, we should
      query points that would reduce uncertainty about the latent optimum, but
      predictive distributions over these latents are intractable, leading to
      complex approximation techniques.
    </p>

    <img
      src="images/figure1.png"
      alt="Probabilistic conditioning and prediction examples"
      class="responsive-img"
    />
    <div class="caption">
      <strong>Probabilistic conditioning and prediction.</strong> Many tasks
      reduce to probabilistic conditioning on data and key latent variables
      (left) and then predicting data and latents (right). (a) Image completion
      and classification. (b) Bayesian optimization. (c) Simulator-based
      inference.
    </div>

    <p>
      We address these challenges by introducing the
      <strong>Amortized Conditioning Engine (ACE)</strong>, a general
      amortization framework that extends transformer-based meta-learning
      architectures with explicit and flexible probabilistic modeling of
      task-relevant latent variables. Through the lens of amortized
      probabilistic conditioning and prediction, we provide a unifying
      methodological bridge across multiple fields.
    </p>

    <h2>Probabilistic Conditioning and Prediction</h2>

    <p>
      In the framework of prediction maps and Conditional Neural Processes
      (CNPs), a prediction map $\pi$ is a function that takes a context set of
      input/output pairs $\mathcal{D}_{N}$ and target inputs
      $\mathbf{x}_{1:M}^*$ to predict a distribution over the corresponding
      target outputs:
    </p>

    $$\pi(y_{1:M}^* | \mathbf{x}_{1:M}^* ; \mathcal{D}_{N}) = p(y_{1:M}^* |
    \mathbf{r}(\mathbf{x}_{1:M}^*, \mathcal{D}_{N}))$$

    <p>
      where $\mathbf{r}$ is a representation vector of the context and target
      sets. Diagonal prediction maps model each target independently:
    </p>

    $$\pi(y_{1:M}^* | \mathbf{x}_{1:M}^* ; \mathcal{D}_{N}) = \prod_{m=1}^{M}
    p(y_{m}^* | \mathbf{r}(\mathbf{x}_{m}^*,
    \mathbf{r}_{\mathcal{D}}(\mathcal{D}_{N})))$$

    <p>
      While diagonal maps directly model conditional 1D marginals, they can
      represent any conditional joint distribution autoregressively.
    </p>

    <h2>The Amortized Conditioning Engine (ACE)</h2>

    <h3>Key Innovation: Encoding Latents and Priors</h3>
    <p>
      ACE extends the prediction map formalism to explicitly accommodate latent
      variables. We redefine inputs as $\boldsymbol{\xi} \in \mathcal{X} \cup
      \{\ell_1, \ldots, \ell_L\}$ where $\mathcal{X}$ is the data input space
      and $\ell_l$ is a marker for the $l$-th latent. Values are redefined as $z
      \in \mathcal{Z}$ where $\mathcal{Z}$ can be continuous or discrete. This
      allows ACE to predict any combination of target variables conditioning on
      any other combination of context data and latents:
    </p>

    $$\pi(z_{1:M}^* | \boldsymbol{\xi}_{1:M}^* ; \mathfrak{D}_{N}) =
    \prod_{m=1}^{M} p(z_{m}^* | \mathbf{r}(\boldsymbol{\xi}_{m}^*,
    \mathbf{r}_{\mathcal{D}}(\mathfrak{D}_{N})))$$

    <blockquote>
      <p>
        <strong>Key Innovation:</strong> ACE also allows the user to express
        probabilistic information over latent variables as prior probability
        distributions at runtime. To flexibly approximate a broad class of
        distributions, we convert each one-dimensional probability density
        function to a normalized histogram of probabilities over a predefined
        grid.
      </p>
    </blockquote>

    <img
      src="images/figure2.png"
      alt="Prior amortization example"
      class="responsive-img"
    />
    <div class="caption">
      <strong>Prior amortization.</strong> Two example posterior distributions
      for the mean $\mu$ and standard deviation $\sigma$ of a 1D Gaussian. (a)
      Prior distribution over $\boldsymbol{\theta}=(\mu, \sigma)$ set at
      runtime. (b) Likelihood for the observed data. (c) Ground-truth Bayesian
      posterior. (d) ACE's predicted posterior approximates well the true
      posterior.
    </div>
    <h3>Architecture</h3>
    <p>ACE consists of three main components:</p>

    <ol>
      <li>
        <strong>Embedding Layer:</strong> Maps context and target data points
        and latents to the same embedding space. For context data points
        $(\mathbf{x}_n, y_n)$, we use $f_{\mathbf{x}}(\mathbf{x}_n) +
        f_{\text{val}}(y_n) + \mathbf{e}_{\text{data}}$, while latent variables
        $\theta_l$ are embedded as $f_{\text{val}}(\theta_l) + \mathbf{e}_l$.
        For latents with a prior $\mathbf{p}_l$, we use
        $f_{\text{prob}}(\mathbf{p}_l) + \mathbf{e}_l$.
      </li>

      <li>
        <strong>Transformer Layers:</strong> ACE employs multi-head
        self-attention for context points and cross-attention from target points
        to context, implemented efficiently to reduce computational complexity.
      </li>

      <li>
        <strong>Output Heads:</strong> For continuous-valued variables, ACE uses
        a Gaussian mixture output consisting of $K$ components. For
        discrete-valued variables, it employs a categorical distribution.
      </li>
    </ol>

    <div class="architecture-details">
      <button
        class="collapsible"
        aria-expanded="false"
        aria-controls="architectureFigure"
      >
        <span class="show-text">Show ACE Architecture Diagram</span>
        <span class="hide-text">Hide ACE Architecture Diagram</span>
        <svg
          class="collapsible-icon"
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          width="24"
          height="24"
        >
          <path d="M12 16L6 10H18L12 16Z" fill="currentColor" />
        </svg>
      </button>
      <div id="architectureFigure" class="content" aria-hidden="true">
        <div class="arch-figure-container">
          <div class="arch-figure-section">
            <img
              src="images/figureS5.png"
              alt="ACE Architecture Diagram showing embedding layer with latent variables, attention blocks, and GMM output head"
              class="responsive-img"
            />
            <div class="caption">
              <strong>A conceptual figure of ACE architecture.</strong>
              ACE's architecture can be summarized in the embedding layer,
              attention layers and output head. The $(\mathbf{x}_n, y_n)$ pairs
              denote known data (context). The red $\mathbf{x}_{j}$ denotes
              locations where the output is unknown (target inputs). The main
              innovation in ACE is that the embedder layer can incorporate known
              or unknown latents $\theta_{l}$ and possibly priors over these.
              The $z$ is the embedded data, while MHSA stands for multi head
              cross attention and CA for cross-attention. The output head is a
              Gaussian mixture model (GMM, for continuous variables) or
              categorical (Cat, for discrete variables). Both latent and data
              can be of either type.
            </div>
          </div>

          <div class="arch-explanation">
            <p>
              The diagram illustrates ACE's key architectural enhancements,
              including:
            </p>
            <ul>
              <li>
                The ability to incorporate latent variables ($\theta$) and their
                priors in the embedder layer
              </li>
              <li>
                More expressive output heads using Gaussian mixture models (GMM)
                or categorical distributions
              </li>
              <li>
                Flexible representation of both continuous and discrete data and
                latent variables
              </li>
            </ul>
            <p>
              These modifications allow ACE to amortize distributions over both
              data and latent variables while maintaining permutation invariance
              for the context set.
            </p>
          </div>
        </div>
      </div>
    </div>

    <div class="highlight">
      <h3>Training and Prediction</h3>
      <p>
        ACE is trained via maximum-likelihood on synthetic data. During
        training, we generate each problem instance hierarchically by first
        sampling the latent variables $\boldsymbol{\theta}$, and then data
        points $(\mathbf{X}, \mathbf{y})$ according to the generative model of
        the task. Data and latents are randomly split between context and
        target.
      </p>
      <p>
        ACE minimizes the expected negative log-likelihood of the target set
        conditioned on the context:
      </p>

      $$\mathcal{L}(\mathbf{w}) = \mathbb{E}_{\mathbf{p} \sim
      \mathcal{P}}\left[\mathbb{E}_{\mathcal{D}_{N}, \boldsymbol{\xi}_{1:M},
      \mathbf{z}_{1:M} \sim \mathbf{p}}\left[-\sum_{m=1}^{M} \log q(z_{m}^* |
      \mathbf{r}_{\mathbf{w}}(\boldsymbol{\xi}_{m}^*,
      \mathfrak{D}_{N}))\right]\right]$$
    </div>

    <h2>Applications and Experimental Results</h2>

    <p>
      We demonstrate ACE's capabilities across diverse machine learning tasks:
    </p>

    <h3>1. Image Completion and Classification</h3>
    <p>
      ACE treats image completion as a regression task, where given limited
      pixel values (context), it predicts the complete image. For MNIST and
      CelebA datasets, ACE outperforms other Transformer Neural Processes, with
      notable improvement when integrating latent information.
    </p>

    <img
      src="images/figure3.png"
      alt="Image completion results"
      class="responsive-img"
    />
    <div class="caption">
      <strong>Image completion.</strong> (a) Reference image. (b) Observed
      pixels (10%). (c-e) Predictions from different models. (f) Performance
      across varying levels of context.
    </div>

    <p>
      ACE also performs well at conditional image generation and image
      classification, as we can condition and predict latent variables such as
      CelebA features.
    </p>
    <img
      src="images/figureS9.png"
      alt="Conditional image completion"
      class="responsive-img"
    />
    <div class="caption">
      <strong>Conditional image completion.</strong> Example of ACE conditioning
      on the value of the BALD feature when the top part of the image is masked.
    </div>

    <h3>2. Bayesian Optimization (BO)</h3>
    <p>
      In Bayesian optimization, ACE explicitly models the global optimum
      location $\mathbf{x}_{\text{opt}}$ and value $y_{\text{opt}}$ as latent
      variables. This enables:
    </p>

    <ul>
      <li>
        Direct sampling from the predictive distribution
        $p(\mathbf{x}_{\text{opt}} | \mathcal{D}_N, y_{\text{opt}} < \tau)$ for
        Thompson Sampling (ACE-TS)
      </li>
      <li>
        Straightforward implementation of Max-Value Entropy Search (MES)
        acquisition function
      </li>
      <li>
        Seamless incorporation of prior information about the optimum location
      </li>
    </ul>

    <img
      src="images/figureS14.png"
      alt="Bayesian Optimization example"
      class="responsive-img-large"
    />
    <div class="caption">
      <strong>Bayesian Optimization.</strong> Example evolution of ACE-TS on a
      1D function. The orange pdf on the left of each panel is $p(y_{\text{opt}}
      | \mathcal{D}_N)$, the red pdf at the bottom of each panel is
      $p(\mathbf{x}_{\text{opt}} | y_{\text{opt}}, \mathcal{D}_N)$, for a
      sampled $y_{\text{opt}}$ (orange dashed-dot line). The queried point at
      each iteration is marked with a red asterisk, while black and blue dots
      represent the observed points. Note how ACE is able to learn complex
      conditional predictive distributions for $\mathbf{x}_{\text{opt}}$ and
      $y_{\text{opt}}$.
    </div>

    <p>
      Results show that ACE-MES frequently outperforms ACE-TS and often matches
      the gold-standard GP-MES. When prior information about the optimum
      location is available, ACE-TS with prior (ACEP-TS) shows significant
      improvement over its no-prior variant and competitive performance compared
      to state-of-the-art methods.
    </p>

    <img
      src="images/figure5.png"
      alt="Bayesian optimization results"
      class="responsive-img-large"
    />
    <div class="caption">
      <strong>Bayesian optimization results.</strong> Regret comparison for
      different methods across benchmark tasks.
    </div>

    <h3>3. Simulation-Based Inference (SBI)</h3>
    <p>
      For simulation-based inference, ACE can predict posterior distributions of
      model parameters, simulate data, predict missing data, and incorporate
      priors at runtime. We evaluated ACE on three simulation models:
    </p>

    <ul>
      <li>Ornstein-Uhlenbeck Process (OUP)</li>
      <li>Susceptible-Infectious-Recovered model (SIR)</li>
      <li>Turin model (a complex radio propagation simulator)</li>
    </ul>

    <p>
      ACE shows performance comparable to dedicated SBI methods on posterior
      estimation. When injecting informative priors (ACEP), performance improves
      proportionally to the provided information. Notably, while Simformer
      achieves similar results, ACE is significantly faster at sampling (0.05
      seconds vs. 130 minutes for 1,000 posterior samples).
    </p>

    <img
      src="images/table1.png"
      alt="Simulator-based inference results table"
      class="responsive-img-large"
    />
    <div class="caption">
      <strong>Comparison metrics for simulator-based inference models.</strong>
      ACE shows performance comparable to dedicated methods while offering
      additional flexibility.
    </div>

    <h2>Conclusions</h2>

    <blockquote>
      <ol>
        <li>
          ACE provides a unified framework for probabilistic conditioning and
          prediction across diverse machine learning tasks.
        </li>
        <li>
          The ability to condition on and predict both data and latent variables
          enables ACE to handle tasks that would otherwise require bespoke
          solutions.
        </li>
        <li>
          Runtime incorporation of priors over latent variables offers
          additional flexibility.
        </li>
        <li>
          Experiments show competitive performance compared to task-specific
          methods across image completion, Bayesian optimization, and
          simulation-based inference.
        </li>
      </ol>
    </blockquote>

    <p>
      ACE shows strong promise as a new unified and versatile method for
      amortized probabilistic conditioning and prediction. While the current
      implementation has limitations, such as quadratic complexity in context
      size and scaling challenges with many data points and latents, these
      provide clear directions for future work.
    </p>

    <h2>References</h2>
    <ol>
      <li>
        Marta Garnelo, Dan Rosenbaum, Chris J Maddison, Tiago Ramalho, David
        Saxton, Murray Shanahan, Yee Whye Teh, Danilo J Rezende, and SM Ali
        Eslami. Conditional neural processes. In International Conference on
        Machine Learning, pages 1704-1713, 2018.
      </li>
      <li>
        Tung Nguyen and Aditya Grover. Transformer Neural Processes:
        Uncertainty-aware meta learning via sequence modeling. In Proceedings of
        the International Conference on Machine Learning (ICML), pages 123-134.
        PMLR, 2022.
      </li>
      <li>
        Samuel Müller, Noah Hollmann, Sebastian Pineda Arango, Josif Grabocka,
        and Frank Hutter. Transformers can do Bayesian inference. In
        International Conference on Learning Representations, 2022.
      </li>
      <li>
        Wessel P Bruinsma, Stratis Markou, James Requeima, Andrew YK Foong, Tom
        R Andersson, Anna Vaughan, Anthony Buonomo, J Scott Hosking, and Richard
        E Turner. Autoregressive conditional neural processes. In International
        Conference on Learning Representations, 2023.
      </li>
      <li>
        Kyle Cranmer, Johann Brehmer, and Gilles Louppe. The frontier of
        simulation-based inference. Proceedings of the National Academy of
        Sciences, 117(48): 30055-30062, 2020.
      </li>
      <li>
        Roman Garnett. Bayesian optimization. Cambridge University Press, 2023.
      </li>
      <li>
        Zi Wang and Stefanie Jegelka. Max-value entropy search for efficient
        Bayesian optimization. In International Conference on Machine Learning,
        pages 3627-3635. PMLR, 2017.
      </li>
      <li>
        Manuel Gloeckler, Michael Deistler, Christian Weilbach, Frank Wood, and
        Jakob H Macke. All-in-one simulation-based inference. In International
        Conference on Machine Learning. PMLR, 2024.
      </li>
    </ol>

    <footer>
      <p>
        © 2025 Paul E. Chang, Nasrulloh Loka, Daolang Huang, Ulpu Remes, Samuel
        Kaski, Luigi Acerbi
      </p>
      <p>
        Code available at:
        <a href="https://github.com/acerbilab/amortized-conditioning-engine/"
          >https://github.com/acerbilab/amortized-conditioning-engine/</a
        >
      </p>
    </footer>
    <!-- Back to top button -->
    <a href="#" id="back-to-top" class="back-to-top" aria-label="Back to top">
      <svg
        xmlns="http://www.w3.org/2000/svg"
        width="24"
        height="24"
        viewBox="0 0 24 24"
        fill="none"
        stroke="currentColor"
        stroke-width="2"
        stroke-linecap="round"
        stroke-linejoin="round"
      >
        <polyline points="18 15 12 9 6 15"></polyline>
      </svg>
    </a>

    <!-- Lightbox container -->
    <div id="lightbox" class="lightbox" aria-hidden="true">
      <div class="lightbox-close" aria-label="Close lightbox">×</div>
      <img class="lightbox-content" id="lightbox-img" src="" alt="" />
    </div>
  </body>

  <script>
    document.addEventListener("DOMContentLoaded", function () {
      // Citation copy functionality
      const citations = document.querySelectorAll(".citation");

      citations.forEach(function (citation, index) {
        // Create the button with Lucide clipboard icon
        const copyBtn = document.createElement("button");
        copyBtn.className = "copy-btn";
        copyBtn.setAttribute("aria-label", "Copy to clipboard");

        // Create SVG icon (Lucide clipboard icon)
        copyBtn.innerHTML = `
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
            <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
          </svg>
        `;

        // Add the button to the citation
        citation.appendChild(copyBtn);

        // Add click event to copy the content
        copyBtn.addEventListener("click", function () {
          // Get the text content, making sure to ignore the SVG content
          const textNodes = Array.from(citation.childNodes)
            .filter(
              (node) =>
                node.nodeType === Node.TEXT_NODE ||
                (node.nodeType === Node.ELEMENT_NODE &&
                  node.tagName !== "BUTTON")
            )
            .map((node) => node.textContent);

          const text = textNodes.join("").trim();

          // Copy to clipboard
          navigator.clipboard
            .writeText(text)
            .then(function () {
              // Enhanced visual feedback with checkmark icon
              copyBtn.innerHTML = `
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                  <polyline points="20 6 9 17 4 12"></polyline>
                </svg>
              `;
              copyBtn.classList.add("copied");
              setTimeout(function () {
                copyBtn.innerHTML = `
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                    <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                    <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                  </svg>
                `;
                copyBtn.classList.remove("copied");
              }, 2000);
            })
            .catch(function (err) {
              console.error("Could not copy text: ", err);
              copyBtn.innerHTML = `
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                  <line x1="18" y1="6" x2="6" y2="18"></line>
                  <line x1="6" y1="6" x2="18" y2="18"></line>
                </svg>
              `;
              setTimeout(function () {
                copyBtn.innerHTML = `
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                    <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
                    <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
                  </svg>
                `;
              }, 2000);
            });
        });
      });

      // Image lightbox functionality
      const lightbox = document.getElementById("lightbox");
      const lightboxImg = document.getElementById("lightbox-img");
      const lightboxClose = document.querySelector(".lightbox-close");
      const images = document.querySelectorAll("img:not(#lightbox-img)");

      // Setup image click listeners
      images.forEach(function (img) {
        img.addEventListener("click", function () {
          lightboxImg.src = this.src;
          lightboxImg.alt = this.alt;
          lightbox.classList.add("active");
          document.body.style.overflow = "hidden"; // Prevent scrolling when lightbox is open
          lightbox.setAttribute("aria-hidden", "false");
        });
      });

      // Close lightbox when clicking the close button
      lightboxClose.addEventListener("click", closeLightbox);

      // Close lightbox when clicking outside the image
      lightbox.addEventListener("click", function (e) {
        if (e.target === lightbox) {
          closeLightbox();
        }
      });

      // Close lightbox when pressing Escape key
      document.addEventListener("keydown", function (e) {
        if (e.key === "Escape" && lightbox.classList.contains("active")) {
          closeLightbox();
        }
      });

      function closeLightbox() {
        lightbox.classList.remove("active");
        document.body.style.overflow = ""; // Restore scrolling
        setTimeout(function () {
          lightboxImg.src = ""; // Clear the source after transition
        }, 300);
        lightbox.setAttribute("aria-hidden", "true");
      }

      // Back to top button functionality
      const backToTopButton = document.getElementById("back-to-top");

      // Show/hide back to top button based on scroll position
      window.addEventListener("scroll", function () {
        if (window.pageYOffset > 300) {
          backToTopButton.classList.add("visible");
        } else {
          backToTopButton.classList.remove("visible");
        }
      });

      // Smooth scroll to top when clicking the button
      backToTopButton.addEventListener("click", function (e) {
        e.preventDefault();

        // Add active class for visual feedback
        this.classList.add("back-to-top-active");

        window.scrollTo({
          top: 0,
          behavior: "smooth",
        });

        // Remove focus and active class after animation completes
        setTimeout(() => {
          this.blur();
          this.classList.remove("back-to-top-active");
        }, 500);
      });

      // Handle touchstart for better mobile response
      backToTopButton.addEventListener(
        "touchstart",
        function (e) {
          this.classList.add("back-to-top-active");
        },
        { passive: true }
      );

      // Handle touchend for mobile devices
      backToTopButton.addEventListener("touchend", function (e) {
        e.preventDefault();

        window.scrollTo({
          top: 0,
          behavior: "smooth",
        });

        // Reset the button state after scroll animation
        setTimeout(() => {
          this.blur();
          this.classList.remove("back-to-top-active");
        }, 500);
      });

      // Ensure the button resets if touch is canceled
      backToTopButton.addEventListener("touchcancel", function () {
        this.classList.remove("back-to-top-active");
      });

      // Smooth scrolling for all anchor links
      document
        .querySelectorAll('a[href^="#"]:not(#back-to-top)')
        .forEach((anchor) => {
          anchor.addEventListener("click", function (e) {
            const href = this.getAttribute("href");

            // Only apply smooth scroll for page anchor links
            if (href !== "#") {
              e.preventDefault();

              const targetElement = document.querySelector(href);
              if (targetElement) {
                targetElement.scrollIntoView({
                  behavior: "smooth",
                });

                // Update URL hash without jumping
                history.pushState(null, null, href);
              }
            }
          });
        });

      // Collapsible section for architecture figure
      const collapsible = document.querySelector(".collapsible");
      const content = document.querySelector(".content");

      if (collapsible && content) {
        collapsible.addEventListener("click", function () {
          const expanded = this.getAttribute("aria-expanded") === "true";

          this.setAttribute("aria-expanded", !expanded);
          content.setAttribute("aria-hidden", expanded);

          if (!expanded) {
            // Open the collapsible
            content.style.maxHeight = content.scrollHeight + "px";
          } else {
            // Close the collapsible
            content.style.maxHeight = "0";
          }
        });

        // Handle keyboard accessibility
        collapsible.addEventListener("keydown", function (e) {
          if (e.key === "Enter" || e.key === " ") {
            e.preventDefault();
            collapsible.click();
          }
        });
      }
    });
  </script>
</html>
