seed: 2
batch_size: 32
eval_batch_size: 100
num_steps: 50000
print_freq: 100
optimizer:
  _target_: torch.optim.Adam
  lr: 0.0005
scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: ${num_steps}
checkpoint: true
ckpt_save_freq: 500
wandb:
  group: ${dataset.name}
  project: amortize-everything
  use_wandb: true
  run_name: FINAL-${dataset.name}-seed=${seed}-${now:%Y-%m-%d_%H-%M-%S}
  tags:
  - dataset=${dataset.name}
  - seed=${seed}
encoder:
  _target_: src.model.encoder.TNPDEncoder
  name: tnpd
  d_model: 64
  dim_feedforward: 128
  n_head: 4
  dropout: 0.0
  num_layers: 6
embedder:
  _target_: src.model.embedder.EmbedderMarkerPriorInjectionBin
  name: mark_emb_skip_prior_injection_bin
  dim_hid: 64
  dim_out: ${encoder.d_model}
  emb_depth: 4
  pos_emb_init: true
  use_skipcon_mlp: true
  num_bins: ${dataset.num_bins}
target_head:
  _target_: src.model.target_head.MixtureGaussian
  name: mixture_gaussian
  dim_y: 1
  d_model: ${encoder.d_model}
  dim_feedforward: 128
  num_components: 20
  single_head: false
  trange: ${dataset.x_range}
  std_min: 0.001
  loss_latent_weight: ${dataset.loss_latent_weight}
  discrete_index: ${dataset.discrete_index}
  loss_data_weight: ${dataset.loss_data_weight}
dataset:
  _target_: src.dataset.sampler_twoway_pi.Sampler
  name: sir_pi
  dim_input: 2
  dim_tar: 1
  num_ctx: random
  x_range:
  - 0
  - 1
  num_latent: 2
  num_bins: 100
  device: cpu
  ctx_tar_sampler: onesidesampler
  n_total_points: 10
  min_ctx_points: 5
  max_ctx_points: 10
  loss_latent_weight: 1
  loss_data_weight: 1
  discrete_index: null
  problem:
    _target_: src.dataset.sbi.sir.SIRPriorInjection
    x_file: data/x_sir_pi_10000.pt
    theta_file: data/theta_sir_pi_10000.pt
    weights_file: data/weights_sir_pi_10000.pt
    batch_size: ${batch_size}
