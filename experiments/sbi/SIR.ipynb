{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957bea34-9a48-48fd-8f3f-442a3d0e3f72",
   "metadata": {},
   "source": [
    "# Simulation-based inference with ACE\n",
    "## SIR task\n",
    "\n",
    "To run this evaluation notebook, please move the notebook to the outside folder under `amortized-conditioning-engine/`, we saved the trained models under `results/sir` for standard task and `results/sir_pi` for ACE with prior injection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981a1991-eab0-472a-8838-cce4e64dbc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.distributions import Uniform, Binomial, LogNormal\n",
    "from hydra import initialize, compose\n",
    "from src.model.base import BaseTransformer\n",
    "from src.dataset.sampler_joint import Sampler\n",
    "from src.dataset.sampler_twoway import Sampler as Sampler_base\n",
    "from src.dataset.sbi.sir import SIR, SIROnline, SIROnlineAll, SIROnlineSamePrior\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import sbi\n",
    "from sbi.utils.torchutils import *\n",
    "from sbi.utils import process_prior\n",
    "from sbi.utils.user_input_checks import *\n",
    "from sbi_demo_utils import *\n",
    "from attrdict import AttrDict\n",
    "import pandas as pd\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "update_plot_style()\n",
    "\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{times}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d2a3f1-e140-40a8-bfc1-5f44254824cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIR_npe(object):\n",
    "    def __init__(self, total_count=1000, T=160):\n",
    "        self.prior = [Uniform(0.01 * torch.ones(1), 1.5 * torch.ones(1)),\n",
    "                     Uniform(0.02 * torch.ones(1), 0.25 * torch.ones(1))]\n",
    "        self.total_count = total_count  # The maximum number of samples for binomial sampling\n",
    "        self.T = T  # The total number of time steps\n",
    "\n",
    "    def sample_theta(self, size):\n",
    "        beta = self.prior[0].sample(size).reshape(-1, 1)\n",
    "        gamma = self.prior[1].sample(size).reshape(-1, 1)\n",
    "        \n",
    "        return torch.cat([beta, gamma], dim=1)\n",
    "\n",
    "    def __call__(self, thetas):\n",
    "        beta = thetas[0]\n",
    "        gamma = thetas[1]\n",
    "        S0, I0, R0 = 999999, 1, 0  # Initial conditions\n",
    "\n",
    "        N_total = S0 + I0 + R0\n",
    "\n",
    "        S = torch.zeros(self.T)\n",
    "        I = torch.zeros(self.T)\n",
    "        R = torch.zeros(self.T)\n",
    "\n",
    "        S[0], I[0], R[0] = S0, I0, R0\n",
    "\n",
    "        # Simulate the SIR model dynamics\n",
    "        for t in range(1, self.T):\n",
    "            new_infections = beta * S[t - 1] * I[t - 1] / N_total\n",
    "            new_recoveries = gamma * I[t - 1]\n",
    "\n",
    "            S[t] = S[t - 1] - new_infections\n",
    "            I[t] = I[t - 1] + new_infections - new_recoveries\n",
    "            R[t] = R[t - 1] + new_recoveries\n",
    "\n",
    "        num_bins = max(1, self.T // 10 + 1)\n",
    "        # Subsample the data, only keep a subset of the infection data\n",
    "        I_subsampled = I[::num_bins]  # Subsampling every `num_bins` steps\n",
    "\n",
    "        I_subsampled = torch.where(I_subsampled < 0, torch.zeros_like(I_subsampled), I_subsampled)\n",
    "        I_subsampled = torch.where(torch.isnan(I_subsampled), torch.zeros_like(I_subsampled), I_subsampled)\n",
    "\n",
    "        I_sampled = Binomial(self.total_count, I_subsampled / N_total).sample()\n",
    "\n",
    "        X = I_sampled / 1000\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa709bb-7b53-42d6-ab82-0135d0a8e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"results/sir/\"\n",
    "cfg_twoway, model_twoway = load_config_and_model(path=path, ckpt_name=\"ckpt_1.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b7b555-0847-4546-98c7-89e7ac92c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "dataset = SIR(x_file=\"data/x_sir_10000.pt\",\n",
    "              theta_file=\"data/theta_sir_10000.pt\",\n",
    "              order=\"fixed\",\n",
    "              batch_size=batch_size)\n",
    "\n",
    "num_ctx_for_ppd = 5\n",
    "\n",
    "# define sampler\n",
    "sampler = Sampler_base(problem=dataset, \n",
    "                       batch_size=batch_size,\n",
    "                       num_ctx=10,\n",
    "                       num_latent=2, \n",
    "                       min_num_points=num_ctx_for_ppd, \n",
    "                       max_num_points=num_ctx_for_ppd+1,\n",
    "                       n_total_points=12,\n",
    "                       ctx_tar_sampler=\"predict_latents_fixed\")\n",
    "\n",
    "eval_set = sampler.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2304c1e4-1c56-4983-8eb8-7a3ec1644063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 2\n",
    "plt.plot(eval_set.xc[seed, :, 1], eval_set.yc[seed, :, 0] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a774426-1dbd-4025-a7dd-f3daa959ae5d",
   "metadata": {},
   "source": [
    "# Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c496b30-08e1-4b85-81d4-16c2837ddf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 101"
     ]
    }
   ],
   "source": [
    "x_npe = torch.load(\"data/x_sir_10000.pt\")\n",
    "theta_npe = torch.load(\"data/theta_sir_10000.pt\")\n",
    "\n",
    "simulator = SIR_npe()\n",
    "prior = simulator.prior\n",
    "prior, *_ = process_prior(prior)\n",
    "\n",
    "# train 5 NPE\n",
    "posterior_npe = []\n",
    "for seed in range(1):\n",
    "    posterior_npe.append(train_npe(prior, theta_npe, x_npe))\n",
    "\n",
    "# train 5 NRE\n",
    "posterior_nre = []\n",
    "for seed in range(5):\n",
    "    posterior_nre.append(train_nre(prior, theta_npe, x_npe))\n",
    "\n",
    "# save trained NPE and NRE\n",
    "save_dir = \"data/npe_posteriors_sir\"\n",
    "for i, posterior in enumerate(posterior_npe):\n",
    "    save_path = os.path.join(save_dir, f\"posterior_npe_{i}.pkl\")\n",
    "    with open(save_path, \"wb\") as handle:\n",
    "        pickle.dump(posterior, handle)\n",
    "\n",
    "save_dir = \"data/nre_posteriors_sir\"\n",
    "for i, posterior in enumerate(posterior_nre):\n",
    "    save_path = os.path.join(save_dir, f\"posterior_nre_{i}.pkl\")\n",
    "    with open(save_path, \"wb\") as handle:\n",
    "        pickle.dump(posterior, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c363205-e3d9-495e-bdd5-ebe0e9f6df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained NPE and NRE\n",
    "save_dir = \"data/npe_posteriors_sir\"\n",
    "posterior_npe = []\n",
    "for i in range(5):\n",
    "    load_path = os.path.join(save_dir, f\"posterior_npe_{i}.pkl\")\n",
    "    with open(load_path, \"rb\") as handle:\n",
    "        posterior_npe.append(pickle.load(handle))\n",
    "\n",
    "save_dir = \"data/nre_posteriors_sir\"\n",
    "posterior_nre = []\n",
    "for i in range(5):\n",
    "    load_path = os.path.join(save_dir, f\"posterior_nre_{i}.pkl\")\n",
    "    with open(load_path, \"rb\") as handle:\n",
    "        posterior_nre.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97299328-697d-468d-9abb-d1182bf00fae",
   "metadata": {},
   "source": [
    "## Evaluation of latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6080a0-a109-4821-8692-bd62fdc4f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 5\n",
    "batch_size = 100\n",
    "dataset = SIROnlineAll(order=\"fixed\")\n",
    "\n",
    "num_ctx_for_ppd = 5\n",
    "\n",
    "# define sampler\n",
    "sampler_joint = Sampler(problem=dataset, \n",
    "                        batch_size=batch_size,\n",
    "                        num_latent=2, \n",
    "                        min_num_points=num_ctx_for_ppd, \n",
    "                        max_num_points=num_ctx_for_ppd+1)\n",
    "\n",
    "eval_set_oneway, eval_set_twoway, eval_set_pi_twoway_narrow, eval_set_pi_twoway_wide = sampler_joint.sample_all_bin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "321de335-b248-4b05-abc1-4ddcd7950d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save eval sets for posterior inference\n",
    "data_dir = \"data/eval_sets_sir\"\n",
    "\n",
    "torch.save(eval_set_oneway, os.path.join(data_dir, \"eval_set_oneway.pt\"))\n",
    "torch.save(eval_set_twoway, os.path.join(data_dir, \"eval_set_twoway.pt\"))\n",
    "torch.save(eval_set_pi_twoway_narrow, os.path.join(data_dir, \"eval_set_pi_twoway_narrow.pt\"))\n",
    "torch.save(eval_set_pi_twoway_wide, os.path.join(data_dir, \"eval_set_pi_twoway_wide.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12cecba1-caa3-40d6-aff3-bc51871ff42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eval sets for posterior inference\n",
    "data_dir = \"data/eval_sets_sir\"\n",
    "\n",
    "eval_set_oneway = torch.load(os.path.join(data_dir, \"eval_set_oneway.pt\"))\n",
    "eval_set_twoway = torch.load(os.path.join(data_dir, \"eval_set_twoway.pt\"))\n",
    "eval_set_pi_twoway_narrow = torch.load(os.path.join(data_dir, \"eval_set_pi_twoway_narrow.pt\"))\n",
    "eval_set_pi_twoway_wide = torch.load(os.path.join(data_dir, \"eval_set_pi_twoway_wide.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e3714c-a676-40b7-9603-4649c74c71aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPE Log probs mean: 6.52683687210083\n",
      "NPE Log probs std: 0.1067903460604361\n",
      "NPE RMSE mean: 0.02395510785281658\n",
      "NPE RMSE std: 0.0005961892939571067\n"
     ]
    }
   ],
   "source": [
    "n_runs = 5\n",
    "\n",
    "# go first with NPE as it takes some time\n",
    "all_log_probs_npe = np.zeros(5)\n",
    "all_rmse_npe = np.zeros(5)\n",
    "\n",
    "for seed in range(n_runs):\n",
    "    \n",
    "    log_probs_npe = torch.zeros([batch_size])\n",
    "    for i in range(batch_size):\n",
    "        log_probs_npe[i] = posterior_npe[seed].log_prob(theta=eval_set_oneway.yt[i].reshape(-1, 2), x=eval_set_oneway.yc[i].reshape(-1, 10))\n",
    "    all_log_probs_npe[seed] = log_probs_npe.mean().numpy()\n",
    "\n",
    "    rmse_npe = torch.zeros([batch_size])\n",
    "    samples_npe_all = torch.empty([batch_size, 2, 200])\n",
    "    for i in range(batch_size):\n",
    "        samples_npe_all[i] = posterior_npe[seed].sample((200,), x=eval_set_oneway.yc[i].reshape(-1, 10), show_progress_bars=False).T\n",
    "    all_rmse_npe[seed] = RMSE(eval_set_oneway.yt, samples_npe_all)\n",
    "\n",
    "print(f\"NPE Log probs mean: {all_log_probs_npe.mean().item()}\")\n",
    "print(f\"NPE Log probs std: {all_log_probs_npe.std().item()}\")\n",
    "\n",
    "print(f\"NPE RMSE mean: {all_rmse_npe.mean().item()}\")\n",
    "print(f\"NPE RMSE std: {all_rmse_npe.std().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24ebbc0-2b4e-4372-9f0a-6a95f1c5c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRE Log probs mean: 6.2398193359375\n",
      "NRE Log probs std: 0.1613214124891001\n",
      "NRE RMSE mean: 0.030018803477287293\n",
      "NRE RMSE std: 0.0030554746456341753\n"
     ]
    }
   ],
   "source": [
    "n_runs = 5\n",
    "\n",
    "# go first with NRE as it takes some time\n",
    "all_log_probs_nre = np.zeros(5)\n",
    "all_rmse_nre = np.zeros(5)\n",
    "\n",
    "for seed in range(n_runs):\n",
    "    \n",
    "    log_probs_nre = torch.zeros([batch_size])\n",
    "    for i in range(batch_size):\n",
    "        log_probs_nre[i] = posterior_nre[seed].log_prob(theta=eval_set_oneway.yt[i].reshape(-1, 2), x=eval_set_oneway.yc[i].reshape(-1, 10))\n",
    "    all_log_probs_nre[seed] = log_probs_nre.mean().numpy()\n",
    "\n",
    "    rmse_npe = torch.zeros([batch_size])\n",
    "    samples_nre_all = torch.empty([batch_size, 2, 100])\n",
    "    for i in range(batch_size):\n",
    "        samples_nre_all[i] = posterior_nre[seed].sample((100,), x=eval_set_oneway.yc[i].reshape(-1, 10), show_progress_bars=False).T\n",
    "    all_rmse_nre[seed] = RMSE(eval_set_oneway.yt, samples_nre_all)\n",
    "\n",
    "print(f\"NRE Log probs mean: {all_log_probs_nre.mean().item()}\")\n",
    "print(f\"NRE Log probs std: {all_log_probs_nre.std().item()}\")\n",
    "\n",
    "print(f\"NRE RMSE mean: {all_rmse_nre.mean().item()}\")\n",
    "print(f\"NRE RMSE std: {all_rmse_nre.std().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293aa601-931f-4d52-a113-530faa52522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE Log probs mean: 6.77625732421875\n",
      "ACE Log probs std: 0.015664397391029844\n",
      "ACE RMSE mean: 0.0208793543279171\n",
      "ACE RMSE std: 0.00019869876860787347\n",
      "ACE PI wide Log probs mean: 6.615552234649658\n",
      "ACE PI wide Log probs std: 0.09752091411045581\n",
      "ACE PI wide RMSE mean: 0.020752278715372087\n",
      "ACE PI wide RMSE std: 0.0006810734078813655\n",
      "ACE PI narrow Log probs mean: 6.691895771026611\n",
      "ACE PI narrow Log probs std: 0.10288250544332034\n",
      "ACE PI narrow RMSE mean: 0.01893892027437687\n",
      "ACE PI narrow RMSE std: 0.0006975083339999629\n"
     ]
    }
   ],
   "source": [
    "all_log_probs_ace = np.zeros(5)\n",
    "all_log_probs_ace_pi_narrow = np.zeros(5)\n",
    "all_log_probs_ace_pi_wide = np.zeros(5)\n",
    "\n",
    "all_rmse_ace= np.zeros(5)\n",
    "all_rmse_ace_pi_narrow = np.zeros(5)\n",
    "all_rmse_ace_pi_wide = np.zeros(5)\n",
    "\n",
    "for seed in range(n_runs):\n",
    "    # two way baseline\n",
    "    path = \"results/sir/\"\n",
    "    cfg_twoway, model_twoway = load_config_and_model(path, \"config.yaml\", f\"ckpt_{seed+1}.tar\")\n",
    "    out_twoway = model_twoway.forward(eval_set_twoway, predict=True)\n",
    "    samples_twoway = out_twoway.samples\n",
    "    log_probs_twoway = -out_twoway.losses.sum(dim=-1)\n",
    "    all_log_probs_ace[seed] = log_probs_twoway.mean().detach().numpy()\n",
    "    all_rmse_ace[seed] = RMSE(eval_set_oneway.yt, samples_twoway)\n",
    "    \n",
    "    \n",
    "    # two way prior injection narrow\n",
    "    path = \"results/sir_pi/\"\n",
    "    cfg_twoway_pi, model_twoway_pi = load_config_and_model(path, \"config.yaml\", f\"ckpt_{seed+1}.tar\")\n",
    "    out_twoway_pi_narrow = model_twoway_pi.forward(eval_set_pi_twoway_narrow, predict=True)\n",
    "    samples_twoway_pi_narrow = out_twoway_pi_narrow.samples\n",
    "    log_probs_twoway_pi_narrow = -out_twoway_pi_narrow.losses.sum(dim=-1)\n",
    "    all_log_probs_ace_pi_narrow[seed] = log_probs_twoway_pi_narrow.mean().detach().numpy()\n",
    "    all_rmse_ace_pi_narrow[seed] = RMSE(eval_set_oneway.yt, samples_twoway_pi_narrow)\n",
    "\n",
    "    # two way prior injection wide\n",
    "    out_twoway_pi_wide = model_twoway_pi.forward(eval_set_pi_twoway_wide, predict=True)\n",
    "    samples_twoway_pi_wide = out_twoway_pi_wide.samples\n",
    "    log_probs_twoway_pi_wide = -out_twoway_pi_wide.losses.sum(dim=-1)\n",
    "    all_log_probs_ace_pi_wide[seed] = log_probs_twoway_pi_wide.mean().detach().numpy()\n",
    "    all_rmse_ace_pi_wide[seed] = RMSE(eval_set_oneway.yt, samples_twoway_pi_wide)\n",
    "\n",
    "print(f\"ACE Log probs mean: {all_log_probs_ace.mean().item()}\")\n",
    "print(f\"ACE Log probs std: {all_log_probs_ace.std().item()}\")\n",
    "print(f\"ACE RMSE mean: {all_rmse_ace.mean().item()}\")\n",
    "print(f\"ACE RMSE std: {all_rmse_ace.std().item()}\")\n",
    "\n",
    "print(f\"ACE PI wide Log probs mean: {all_log_probs_ace_pi_wide.mean().item()}\")\n",
    "print(f\"ACE PI wide Log probs std: {all_log_probs_ace_pi_wide.std().item()}\")\n",
    "print(f\"ACE PI wide RMSE mean: {all_rmse_ace_pi_wide.mean().item()}\")\n",
    "print(f\"ACE PI wide RMSE std: {all_rmse_ace_pi_wide.std().item()}\")\n",
    "\n",
    "print(f\"ACE PI narrow Log probs mean: {all_log_probs_ace_pi_narrow.mean().item()}\")\n",
    "print(f\"ACE PI narrow Log probs std: {all_log_probs_ace_pi_narrow.std().item()}\")\n",
    "print(f\"ACE PI narrow RMSE mean: {all_rmse_ace_pi_narrow.mean().item()}\")\n",
    "print(f\"ACE PI narrow RMSE std: {all_rmse_ace_pi_narrow.std().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036efa30-07be-4496-834c-7eb3b5b624c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE Log probs mean: 6.815367221832275\n",
      "ACE Log probs std: 0.02252022626129036\n",
      "ACE RMSE mean: 0.020190023258328436\n",
      "ACE RMSE std: 0.00014964938430371455\n"
     ]
    }
   ],
   "source": [
    "n_runs=5\n",
    "\n",
    "all_log_probs_ace = np.zeros(5)\n",
    "\n",
    "all_rmse_ace= np.zeros(5)\n",
    "\n",
    "for seed in range(n_runs):\n",
    "    # two way baseline\n",
    "    path = \"results/sir_gaussian_head/\"\n",
    "    cfg_twoway, model_twoway = load_config_and_model(path, \"config.yaml\", f\"ckpt_{seed+1}.tar\")\n",
    "    out_twoway = model_twoway.forward(eval_set_twoway, predict=True)\n",
    "    samples_twoway = out_twoway.samples.squeeze(-1)\n",
    "    log_probs_twoway = -out_twoway.losses.sum(dim=-1)\n",
    "    all_log_probs_ace[seed] = log_probs_twoway.mean().detach().numpy()\n",
    "    all_rmse_ace[seed] = RMSE(eval_set_oneway.yt, samples_twoway)\n",
    "\n",
    "print(f\"ACE Log probs mean: {all_log_probs_ace.mean().item()}\")\n",
    "print(f\"ACE Log probs std: {all_log_probs_ace.std().item()}\")\n",
    "print(f\"ACE RMSE mean: {all_rmse_ace.mean().item()}\")\n",
    "print(f\"ACE RMSE std: {all_rmse_ace.std().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b0d83-decb-41b8-8948-286baa69d119",
   "metadata": {},
   "source": [
    "## Evaluation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eac6b01f-1f51-4345-9aed-d308e88cba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_way = 3\n",
    "eval_set_ppd, eval_set_ppd_pi_narrow, eval_set_ppd_pi_wide = sampler_joint.sample_ppd(sampling_way, know_theta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2dc79787-afd4-49a8-ab08-3f4d116676f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save eval sets for data prediction\n",
    "data_dir = \"data/eval_sets_ppd_sir\"\n",
    "\n",
    "torch.save(eval_set_ppd, os.path.join(data_dir, \"eval_set_ppd.pt\"))\n",
    "torch.save(eval_set_ppd_pi_narrow, os.path.join(data_dir, \"eval_set_ppd_pi_narrow.pt\"))\n",
    "torch.save(eval_set_ppd_pi_wide, os.path.join(data_dir, \"eval_set_ppd_pi_wide.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7592959-7863-4b6d-a2d4-25abe2ef5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eval sets for posterior inference\n",
    "data_dir = \"data/eval_sets_ppd_sir\"\n",
    "\n",
    "eval_set_ppd = torch.load(os.path.join(data_dir, \"eval_set_ppd.pt\"))\n",
    "eval_set_ppd_pi_narrow = torch.load(os.path.join(data_dir, \"eval_set_ppd_pi_narrow.pt\"))\n",
    "eval_set_ppd_pi_wide = torch.load(os.path.join(data_dir, \"eval_set_ppd_pi_wide.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5404fbfd-5f9f-4fe7-aa3d-cc80188fcd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE-2 PPD MMD mean: 0.021445966482162477\n",
      "ACE-2 PPD MMD std: 0.002784674995888478\n",
      "ACE-2 PPD PI wide MMD mean: 0.016392988085746768\n",
      "ACE-2 PPD PI wide MMD std: 0.0010298195598768664\n",
      "ACE-2 PPD PI narrow MMD mean: 0.0001823153495788574\n",
      "ACE-2 PPD PI narrow MMD std: 2.3142080723829608e-05\n"
     ]
    }
   ],
   "source": [
    "all_mmd_ppd_ace = np.zeros(5)\n",
    "all_mmd_ppd_ace_pi_narrow = np.zeros(5)\n",
    "all_mmd_ppd_ace_pi_wide = np.zeros(5)\n",
    "\n",
    "for seed in range(n_runs):\n",
    "    # two way baseline\n",
    "    path = \"results/sir/\"\n",
    "    cfg_twoway, model_twoway = load_config_and_model(path, \"config.yaml\", f\"ckpt_{seed+1}.tar\")\n",
    "    out_ppd_twoway = model_twoway.forward(eval_set_ppd, predict=True)\n",
    "    samples_ppd_twoway = out_ppd_twoway.samples\n",
    "    mmd = 0\n",
    "    for i in range(batch_size):\n",
    "        mmd += float(MMD_unweighted(samples_ppd_twoway[i].T, eval_set_ppd.yt[i].T, lengthscale=1))\n",
    "    all_mmd_ppd_ace[seed] = mmd / batch_size\n",
    "\n",
    "    # two way prior injection narrow\n",
    "    path = \"results/sir_pi/\"\n",
    "    cfg_twoway_pi, model_twoway_pi = load_config_and_model(path, \"config.yaml\", f\"ckpt_{seed+1}.tar\")\n",
    "    out_ppd_twoway_pi_narrow = model_twoway_pi.forward(eval_set_ppd_pi_narrow, predict=True)\n",
    "    samples_ppd_pi_twoway_narrow = out_ppd_twoway_pi_narrow.samples\n",
    "    mmd = 0\n",
    "    for i in range(batch_size):\n",
    "       mmd += float(MMD_unweighted(samples_ppd_pi_twoway_narrow[i, :-2, :].T, eval_set_ppd_pi_narrow.yt[i, :-2, :].T, lengthscale=1))\n",
    "    all_mmd_ppd_ace_pi_narrow[seed] = mmd / batch_size\n",
    "\n",
    "    # two way prior injection wide\n",
    "    out_ppd_twoway_pi_wide = model_twoway_pi.forward(eval_set_ppd_pi_wide, predict=True)\n",
    "    samples_ppd_pi_twoway_wide = out_ppd_twoway_pi_wide.samples\n",
    "    mmd = 0\n",
    "    for i in range(batch_size):\n",
    "       mmd += float(MMD_unweighted(samples_ppd_pi_twoway_wide[i, :-2, :].T, eval_set_ppd_pi_wide.yt[i, :-2, :].T, lengthscale=1))\n",
    "    all_mmd_ppd_ace_pi_wide[seed] = mmd / batch_size\n",
    "\n",
    "print(f\"ACE-2 PPD MMD mean: {all_mmd_ppd_ace.mean().item()}\")\n",
    "print(f\"ACE-2 PPD MMD std: {all_mmd_ppd_ace.std().item()}\")\n",
    "\n",
    "print(f\"ACE-2 PPD PI wide MMD mean: {all_mmd_ppd_ace_pi_wide.mean().item()}\")\n",
    "print(f\"ACE-2 PPD PI wide MMD std: {all_mmd_ppd_ace_pi_wide.std().item()}\")\n",
    "\n",
    "print(f\"ACE-2 PPD PI narrow MMD mean: {all_mmd_ppd_ace_pi_narrow.mean().item()}\")\n",
    "print(f\"ACE-2 PPD PI narrow MMD std: {all_mmd_ppd_ace_pi_narrow.std().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bfdb3b5-e4e7-404e-a477-20c06c75c7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE-2 PPD MMD mean: 0.021102903842926027\n",
      "ACE-2 PPD MMD std: 0.00351557954746998\n"
     ]
    }
   ],
   "source": [
    "all_mmd_ppd_ace = np.zeros(5)\n",
    "\n",
    "for seed in range(n_runs):\n",
    "    # two way baseline\n",
    "    path = \"results/sir_gaussian_head/\"\n",
    "    cfg_twoway, model_twoway = load_config_and_model(path, \"config.yaml\", f\"ckpt_{seed+1}.tar\")\n",
    "    out_ppd_twoway = model_twoway.forward(eval_set_ppd, predict=True)\n",
    "    samples_ppd_twoway = out_ppd_twoway.samples.squeeze(-1)\n",
    "    mmd = 0\n",
    "    for i in range(batch_size):\n",
    "        mmd += float(MMD_unweighted(samples_ppd_twoway[i].T, eval_set_ppd.yt[i].T, lengthscale=1))\n",
    "    all_mmd_ppd_ace[seed] = mmd / batch_size\n",
    "\n",
    "print(f\"ACE-2 PPD MMD mean: {all_mmd_ppd_ace.mean().item()}\")\n",
    "print(f\"ACE-2 PPD MMD std: {all_mmd_ppd_ace.std().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8de1517-017c-4c04-8a2a-a91df96ad40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_log_probs_npe, \"results/metrics/sir_log_probs_npe.npy\")\n",
    "torch.save(all_log_probs_nre, \"results/metrics/sir_log_probs_nre.npy\")\n",
    "torch.save(all_log_probs_ace, \"results/metrics/sir_log_probs_ace.npy\")\n",
    "torch.save(all_log_probs_ace_pi_narrow, \"results/metrics/sir_log_probs_ace_narrow.npy\")\n",
    "torch.save(all_log_probs_ace_pi_wide, \"results/metrics/sir_log_probs_ace_wide.npy\")\n",
    "\n",
    "torch.save(all_rmse_npe, \"results/metrics/sir_rmse_npe.npy\")\n",
    "torch.save(all_rmse_nre, \"results/metrics/sir_rmse_nre.npy\")\n",
    "torch.save(all_rmse_ace, \"results/metrics/sir_rmse_ace.npy\")\n",
    "torch.save(all_rmse_ace_pi_narrow, \"results/metrics/sir_rmse_ace_narrow.npy\")\n",
    "torch.save(all_rmse_ace_pi_wide, \"results/metrics/sir_rmse_ace_wide.npy\")\n",
    "\n",
    "torch.save(all_mmd_ppd_ace, \"results/metrics/sir_mmd_ace.npy\")\n",
    "torch.save(all_mmd_ppd_ace_pi_narrow, \"results/metrics/sir_mmd_ace_narrow.npy\")\n",
    "torch.save(all_mmd_ppd_ace_pi_wide, \"results/metrics/sir_mmd_ace_wide.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ace]",
   "language": "python",
   "name": "conda-env-ace-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
