defaults:
  - _self_
  - encoder: tnpd
  - embedder: embedder_marker_prior_sbi  # embedder_marker_prior_sbi for prior injection, or embedder_marker_skipcon for no prior injection
  - target_head: mixture_head
  - dataset: sir_prior  # sir, sir_prior, oup, oup_prior, turin, turin_prior

seed: 10
batch_size: 32

eval_batch_size: 100
num_steps: 50000
print_freq: 100

optimizer:
  _target_: torch.optim.Adam
  lr: 5e-4

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: ${num_steps} # match num_steps in training

checkpoint: True
ckpt_save_freq: 500

##### W&B config #####
wandb:
  group: ${dataset.name}
  project: "amortized-conditioning-engine"
  use_wandb: False
  run_name: ${dataset.name}-seed=${seed}-${now:%Y-%m-%d_%H-%M-%S}
  tags:
    - "dataset=${dataset.name}"
    - "seed=${seed}"
